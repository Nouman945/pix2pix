{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "# Define the transformation (should match what was used during training)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize images to the same size as used during training\n",
    "    transforms.ToTensor(),          # Convert images to tensors\n",
    "])\n",
    "\n",
    "# Load your three input images\n",
    "img_bright = Image.open('/path/to/bright_image.jpg')\n",
    "img_mid = Image.open('/path/to/mid_image.jpg')\n",
    "img_dark = Image.open('/path/to/dark_image.jpg')\n",
    "\n",
    "# Apply transformations\n",
    "img_bright = transform(img_bright)\n",
    "img_mid = transform(img_mid)\n",
    "img_dark = transform(img_dark)\n",
    "\n",
    "# Combine the images into a single multi-channel tensor\n",
    "input_image = torch.cat((img_bright, img_mid, img_dark), dim=0)\n",
    "input_image = input_image.unsqueeze(0)  # Add a batch dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from options.test_options import TestOptions\n",
    "from models import create_model\n",
    "\n",
    "# Simulate Command-Line Arguments for Testing\n",
    "sys.argv = [\n",
    "    'test.py',\n",
    "    '--dataroot', '/media/nouman/New Volume/realEstatePhoto/RealEstateDataset',\n",
    "    '--name', 'real_estate_pix2pix',\n",
    "    '--model', 'pix2pix',\n",
    "    '--direction', 'AtoB',\n",
    "    '--input_nc', '9',  # 3 channels for each of bright, mid, dark\n",
    "    '--output_nc', '3',  # 3 channels for the final image\n",
    "    '--gpu_ids', '0',\n",
    "    '--no_dropout'\n",
    "]\n",
    "\n",
    "# Parse options for testing\n",
    "opt = TestOptions().parse()\n",
    "\n",
    "# Create and load the model\n",
    "model = create_model(opt)\n",
    "model.setup(opt)\n",
    "model.load_networks('latest')  # Load the latest saved model\n",
    "model.eval()  # Set model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a dictionary to mimic the dataloader output\n",
    "data = {\n",
    "    'A': input_image,  # The concatenated image (3 channels each for bright, mid, dark)\n",
    "    'A_paths': '/path/to/bright_image.jpg'  # You can add paths if needed\n",
    "}\n",
    "\n",
    "# Set the input to the model\n",
    "model.set_input(data)\n",
    "\n",
    "# Run inference\n",
    "model.test()  # Forward pass for testing\n",
    "\n",
    "# Get the generated output\n",
    "visuals = model.get_current_visuals()\n",
    "generated_output = visuals['fake_B']\n",
    "\n",
    "# Convert the output to a PIL image and display it\n",
    "output_image = transforms.ToPILImage()(generated_output.squeeze(0).cpu())\n",
    "\n",
    "# Optionally display the image\n",
    "output_image.show()\n",
    "\n",
    "# Save the output image\n",
    "output_image.save('/path/to/save/generated_image.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display the input and output images\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Display the bright input image\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(transforms.ToPILImage()(img_bright.cpu()))\n",
    "plt.title('Input Bright')\n",
    "\n",
    "# Display the mid input image\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(transforms.ToPILImage()(img_mid.cpu()))\n",
    "plt.title('Input Mid')\n",
    "\n",
    "# Display the dark input image\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(transforms.ToPILImage()(img_dark.cpu()))\n",
    "plt.title('Input Dark')\n",
    "\n",
    "# Display the generated output image\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(output_image)\n",
    "plt.title('Generated Output')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
